{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s-vHqmrmiHg7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import preprocessing\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, tpe\n",
    "\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_path = \"/Users/alexk/Documents/GitHub/Deep_Learning_for_Binary_Classification_of_Infectious_Keratitis/data\"\n",
    "x_test = []\n",
    "# Put all hyperparameters in a dictionary\n",
    "hyperparameters = {'batch_size': 128,\n",
    "                   'random_flip': 'horizontal_and_vertical',\n",
    "                   'random_rotation': (0.2),\n",
    "                   'dropout': 0.5,\n",
    "                   'L2': 0.3,\n",
    "                   'base_LR': 0.001,\n",
    "                   'initial_epochs': 20,\n",
    "                   'fine_tune_epochs': 50,\n",
    "                   'frozen_layer': 72}\n",
    "\n",
    "# Declare all necessary variables\n",
    "BATCH_SIZE = hyperparameters['batch_size']\n",
    "IMG_SIZE = (224, 224)\n",
    "path = \"/Users/alexk/Documents/GitHub/Deep_Learning_for_Binary_Classification_of_Infectious_Keratitis/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def listdir_nohidden(path):\n",
    "    for f in os.listdir(path):\n",
    "        if not f.startswith('.'):\n",
    "            yield f\n",
    "\n",
    "for folder in listdir_nohidden(test_path):\n",
    "\n",
    "    sub_path=test_path+\"/\"+folder\n",
    "\n",
    "    for img in listdir_nohidden(sub_path):\n",
    "\n",
    "        image_path=sub_path+\"/\"+img\n",
    "\n",
    "        img_arr=cv2.imread(image_path)\n",
    "\n",
    "        img_arr=cv2.resize(img_arr,(224,224))\n",
    "\n",
    "        x_test.append(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#predicted_classes = np.argmax(mlpmixer_classifier.predict(X, axis = 1))\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_x=np.array(x_test)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "test_y=test_set.classes\n",
    "\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 671 files belonging to 2 classes.\n",
      "Using 537 files for training.\n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 64.00 GB\n",
      "maxCacheSize: 24.00 GB\n",
      "\n",
      "Found 671 files belonging to 2 classes.\n",
      "Using 134 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess images to the standard for a MobileNetV2\n",
    "train_dataset = keras.preprocessing.image_dataset_from_directory(path,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 subset='training',\n",
    "                                                                 seed=42,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE,\n",
    "                                                                 validation_split=0.2,\n",
    "                                                                 label_mode='categorical',\n",
    "                                                                 class_names=['Bacterial', 'Fungal'])\n",
    "validation_dataset = keras.preprocessing.image_dataset_from_directory(path,\n",
    "                                                                      shuffle=True,\n",
    "                                                                      subset='validation',\n",
    "                                                                      seed=42,\n",
    "                                                                      batch_size=BATCH_SIZE,\n",
    "                                                                      validation_split=0.2,\n",
    "                                                                      image_size=IMG_SIZE,\n",
    "                                                                      label_mode='categorical',\n",
    "                                                                      class_names=['Bacterial', 'Fungal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nZ4XJmA2TGHT",
    "outputId": "98155699-5340-4c85-9647-a8b2159d63b2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " sequential_1 (Sequential)   (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 224, 224, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 224, 224, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_224 (Funct  (None, 7, 7, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,260,546\n",
      "Trainable params: 2,095,618\n",
      "Non-trainable params: 164,928\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 21:38:52.553524: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 21s 2s/step - loss: 2.4293 - accuracy: 0.5903 - auc: 0.6023 - val_loss: 1.8234 - val_accuracy: 0.6343 - val_auc: 0.6219\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 94\u001b[0m\n\u001b[1;32m     89\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m hyperparameters[\u001b[39m'\u001b[39m\u001b[39mbase_LR\u001b[39m\u001b[39m'\u001b[39m]),\n\u001b[1;32m     90\u001b[0m                              loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     91\u001b[0m                              metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     93\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39m/job:localhost/replica:0/task:0/device:CPU:0\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 94\u001b[0m     history_adam \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset,\n\u001b[1;32m     95\u001b[0m                          validation_data\u001b[39m=\u001b[39;49mvalidation_dataset,\n\u001b[1;32m     96\u001b[0m                          epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[1;32m     99\u001b[0m \u001b[39m# Achieves a 0.9552 peak validation accuracy indicating that MobileNet can handle data augmentation\u001b[39;00m\n\u001b[1;32m    100\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1377\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1378\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1379\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1380\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1381\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1382\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1383\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1384\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1385\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1386\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2953\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2954\u001b[0m   (graph_function,\n\u001b[1;32m   2955\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2957\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1849\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1850\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1851\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1852\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1853\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1854\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1855\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m     args,\n\u001b[1;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1858\u001b[0m     executing_eagerly)\n\u001b[1;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/WSSEF_Project/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    def data_augmenter():\n",
    "        \"\"\"\n",
    "            Create a sequential model composed of horizontal flips and random contrast adjustments\n",
    "        \"\"\"\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip(hyperparameters['random_flip']),\n",
    "            tf.keras.layers.RandomRotation(factor=hyperparameters['random_rotation'])])\n",
    "        return data_augmentation\n",
    "\n",
    "data_augmentation = data_augmenter()\n",
    "\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "conv_base = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                              include_top=False,\n",
    "                                              weights='imagenet')\n",
    "\n",
    "\n",
    "def MobileNetUlcerModel(image_shape=IMG_SIZE, data_augmentation=data_augmenter()):\n",
    "    # freeze the convolutional base\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    # create the input layer\n",
    "    inputs = tf.keras.Input(shape=IMG_SHAPE)\n",
    "\n",
    "    # apply data augmentation to the inputs\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # data preprocessing using the same weights as the original pre-trained model\n",
    "    x = tf.keras.applications.mobilenet_v2.preprocess_input(x)\n",
    "\n",
    "    # set training to False to avoid keeping track of statistics in the batch norm layer\n",
    "    x = conv_base(x, training=False)\n",
    "\n",
    "    # Add the new binary classification layers\n",
    "    # global average pooling layer\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # include dropout for regularization effect\n",
    "    x = tf.keras.layers.Dropout(hyperparameters['dropout'])(x)\n",
    "\n",
    "    # Add binary prediction layer\n",
    "    outputs = tf.keras.layers.Dense(2, activation='softmax', kernel_regularizer=regularizers.l2(hyperparameters['L2']))(x)\n",
    "\n",
    "    # Add sigmoid output layer if necessary (use AUC for classification metric of prediction)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = MobileNetUlcerModel()\n",
    "\n",
    "base_learning_rate = hyperparameters['base_LR']\n",
    "\n",
    "conv_base = model.layers[4]\n",
    "\n",
    "conv_base.trainable = True\n",
    "\n",
    "for layer in conv_base.layers[:hyperparameters['frozen_layer']]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#model.summary()\n",
    "# Compile the mobilenet using an RMSprop optimizer (gradient descent based optimizer)\n",
    "#model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.1 * hyperparameters['base_LR']),\n",
    "#              loss='binary_crossentropy', # measuring the loss using the binary cross-entropy function\n",
    "#              metrics=['accuracy', 'AUC']) # metrics of accuracy are AUC and accuracy\n",
    "\n",
    "#with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "#    history = model.fit(train_dataset,\n",
    "#                        epochs=hyperparameters['fine_tune_epochs'],\n",
    "#                        validation_data=validation_dataset)\n",
    "\n",
    "#model.summary()\n",
    "# SGD based optimizer for MobileNetV2 (Gradient descent optimization)\n",
    "#model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.1 * hyperparameters['base_LR']),\n",
    "#              loss='binary_crossentropy',\n",
    "#              metrics=['accuracy', 'AUC'])\n",
    "\n",
    "#with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "#    history_sgd = model.fit(train_dataset,\n",
    "#                            validation_data=validation_dataset,\n",
    "#                            epochs=hyperparameters['fine_tune_epochs'])\n",
    "\n",
    "model.summary()\n",
    "#Base learning rate Adam optimized MobileNetV2\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.1 * hyperparameters['base_LR']),\n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['accuracy', 'AUC'])\n",
    "\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    history_adam = model.fit(train_dataset,\n",
    "                         validation_data=validation_dataset,\n",
    "                         epochs=30)\n",
    "\n",
    "\n",
    "# Achieves a 0.9552 peak validation accuracy indicating that MobileNet can handle data augmentation\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.1 * hyperparameters['base_LR']),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'AUC'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    )\n",
    "\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    history_tuning = model.fit(train_dataset,\n",
    "                            epochs=hyperparameters['fine_tune_epochs'],\n",
    "                            validation_data=validation_dataset,\n",
    "                               callbacks=[early_stopping])\n",
    "\n",
    "df_loss_acc = pd.DataFrame(history_tuning.history)\n",
    "df_loss = df_loss_acc[['loss', 'val_loss']]\n",
    "df_loss.rename(columns={'loss': 'train', 'val_loss': 'validation'}, inplace=True)\n",
    "df_acc = df_loss_acc[['accuracy', 'val_accuracy']]\n",
    "df_acc.rename(columns={'accuracy': 'train', 'val_accuracy': 'validation'}, inplace=True)\n",
    "df_auc = df_loss_acc[['auc', 'val_auc']]\n",
    "df_auc.rename(columns={'auc': 'train', 'val_auc': 'validation'}, inplace=True)\n",
    "df_loss.plot(title='Model loss', figsize=(12, 8)).set(xlabel='Epoch', ylabel='Loss')\n",
    "df_auc.plot(title='Model AUC', figsize=(12, 8)).set(xlabel='Epoch', ylabel='AUC')\n",
    "df_acc.plot(title='Model Accuracy', figsize=(12, 8)).set(xlabel='Epoch', ylabel='Accuracy')\n",
    "plt.show()\n",
    "\n",
    "#model.save('/content/drive/MyDrive/Machine Learning Research Files/LeNet and MobileNetV2 For Binary Classification of Infectious Keratitis/LeNet-MobileNetV2-For-Binary-Classification-of-Infectious-Keratitis/models/MobileNet_whole_image_fine_tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[174  57]\n",
      " [ 54 386]]\n",
      "0.871331828442438\n",
      "0.7631578947368421\n",
      "0.834575260804769\n"
     ]
    }
   ],
   "source": [
    "mobilenet_predicted_classes = np.argmax(model.predict(test_x), axis=1)\n",
    "mobilenet_cm = confusion_matrix(test_y, mobilenet_predicted_classes)\n",
    "print(mobilenet_cm)\n",
    "\n",
    "mobilenet_TN = mobilenet_cm[0][0]\n",
    "mobilenet_FN = mobilenet_cm[0][1]\n",
    "mobilenet_FP = mobilenet_cm[1][0]\n",
    "mobilenet_TP = mobilenet_cm[1][1]\n",
    "mobilenet_sensitivity = mobilenet_TP / (mobilenet_TP + mobilenet_FN)\n",
    "mobilenet_specificity = mobilenet_TN / (mobilenet_TN + mobilenet_FP)\n",
    "\n",
    "mobilenet_accuracy = (mobilenet_TP + mobilenet_TN) / 671\n",
    "\n",
    "print(mobilenet_sensitivity)\n",
    "print(mobilenet_specificity)\n",
    "print(mobilenet_accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "WEV76fuBbhrR"
   ],
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "WSSEF_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 | packaged by conda-forge | (default, Jan 30 2022, 23:13:24) \n[Clang 11.1.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2be4f563159ad1d05af3857161bd1547d22826cd1b05499c5795c7ab3009f568"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
